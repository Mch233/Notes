#0. 支持向量机 #
二分类模型

分类决策函数（分离超平面）

间隔最大化 --> 最优分离超平面 （唯一）

----------

## 基本模型 ##
：定义在特征空间上的间隔最大的线性分类器

## 学习策略 ##
：间隔最大化，求解凸二次规划的最优化

## 主要模型 ##
1.训练数据线性可分，通过硬间隔最大化，学得线性可分支持向量机

2.训练数据近似线性可分，通过软间隔最大化，学得线性支持向量机

3.训练数据线性不可分，通过核技巧和软间隔最大化，学得非线性支持向量机

## 核技巧 ##
在高维的特征空间中学习线性支持向量机
----------

输入空间：欧式空间或离散集合

特征空间：希尔伯特空间

核函数表示 将 输入 从 输入空间 映射 到 特征空间 得到的 特征向量之间的内积

## 拉格朗日对偶性 ##
应用拉格朗日对偶性，将 原始问题   ————> 对偶问题

通过解对偶问题得到原始问题的解

## 函数间隔和几何间隔 ##
函数间隔：一个点距离超平面的距离；y轴距离

引入函数间隔 表示分类的正确性和确信度

几何间隔：对函数间隔增加约束；垂直距离

## 对偶算法 ##
优点：1.更容易求解。2.自然引入核函数，推广到非线性分类

# 2.线性支持向量机 #
算法不再适用，不等式约束不能都成立

如何扩展到线性不可分问题？

								对样本点引入	松弛变量	

软间隔的支持向量xi 

					或着在间隔边界上
					或者在间隔边界与分离超平面之间
					或者在分离超平面误分一侧


# 3.非线性支持向量机 #

非线性变换；将非线性问题变换为线性问题

将线性支持向量机对偶形式中的内积换成核函数

----------

用线性分类方法求解非线性分类问题分为两步

	1.使用一个变换将原空间的数据映射到新空间
	
	2.在新空间里用线性分类学习方法从训练数据中学习分类模型

核函数选择的有效性需要通过实验验证

满足什么条件才能成为核函数？

根据核函数，构成一个希尔伯特空间的步骤

	1.定义映射，构成向量空间s
	2.在s上定义内积，构成内积空间
	3.将s完备化构成希尔伯特空间

常用核函数

	1.多项式核函数
	2.高斯核函数
	3.字符串核函数

## 4.序列最小最优化算法 ##

SMO算法

	1.求解两个变量二次规划的解析方法
	2.选择变量的启发式方法
