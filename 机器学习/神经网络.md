## 神经元 ##
模型

![](https://i.imgur.com/LsDw7WI.png)

激活函数

![](https://i.imgur.com/nzSCB54.png)

----------

# 神经网络 #

权重、连接、层数、激活函数（可微）、阈值、误差函数、权值更新方法



----------

![](https://i.imgur.com/PIyOxfa.png)

训练神经网络：

				1. 参数的随机初始化
				2. 利用正向传播方法计算所有的 hθ(x) 即假设函数
				3. 编写计算代价函数 J 	
				4. 利用反向传播方法计算所有偏导数
				5. 利用数值检验方法检验这些偏导数
				6. 使用优化算法来最小化代价函数


## 代价函数 ##

拟合参数的优化目标

![](https://i.imgur.com/jCKCQ1q.png)

## 终止条件 ##
	1.误差阈值
	2.固定迭代次数
	3.验证样例误差标准
	

## BP多层前馈神经网络 ##
以神经元为基本单位逐层拟合

1.写出假设函数

2.均方误差

3.计算导数

4.计算梯度下降公式

5.更新权重公式

	学习率*（偏导数*误差）*输入

## BP算法变体 ##
	1.权值更新，增加冲量项


## 其他常见的神经网络 ##

	1.RBF：
			激活函数：径向基函数
			输出层：隐层神经元输出的线性组合

	2.ART:
			无监督学习，只有一个神经元激活，阈值影响大

	3.SOM（自组织映射网络）:	

	4.级联相关网络（结构自适应网络）：	

	5.Elman（递归神经网络）：	
							输出反馈输入

	6.Biltzmann（玻尔兹曼机）：	
								能量，最小化能量函数

	7.深度学习：	特征学习
						DBN（深度信念网络）：	Wake-Sleep自动编码器 & RBM受限玻尔兹曼机
					
			预训练 + 微调、BP
						
						CNN（卷积神经网络）：	
								
			
			


## 过拟合 ##
	早停
	正则化

## 避免局部最小 ##

	1.随机初始多次权重计算
	2.模拟退火 ，一定概率接受次解
	3.随机梯度下降